{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BzK5MqC3NLZ"
      },
      "source": [
        "## Yol Belirleme\n",
        "Bu arada Google Drive içinde çalışacağınız klasörü belirlemeniz gerekmektedir. Veri seti düzenleme veya model eğitimi için burayı yeniden çalıştırın."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L8V0KIx-29cO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l53mto03Loj"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Veri-Kazima/unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiFoeWVP3Mq0"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiR4P1q088rC"
      },
      "source": [
        "## Gerekli Kütüphaneleri Yükleyin\n",
        "Burada model eğitimi, model çalıştırma için buraya yeniden gelebilirsiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade unsloth xformers bitsandbytes transformers peft datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade unsloth xformers bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade xformers bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n5v31Cnq4IFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting torch\n",
            "  Using cached torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
            "Collecting peft\n",
            "  Using cached peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.45.2-py3-none-win_amd64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.17.0)\n",
            "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: fsspec in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from peft) (7.0.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.5.0)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Using cached aiohttp-3.11.12-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (2.4.6)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "Using cached torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
            "Using cached peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Using cached accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Using cached bitsandbytes-0.45.2-py3-none-win_amd64.whl (69.1 MB)\n",
            "Using cached aiohttp-3.11.12-cp311-cp311-win_amd64.whl (442 kB)\n",
            "Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multiprocess, jinja2, aiosignal, torch, huggingface-hub, aiohttp, tokenizers, bitsandbytes, accelerate, transformers, datasets, peft\n",
            "Successfully installed accelerate-1.4.0 aiohttp-3.11.12 aiosignal-1.3.2 bitsandbytes-0.45.2 datasets-3.3.2 huggingface-hub-0.29.1 jinja2-3.1.5 multiprocess-0.70.16 peft-0.14.0 tokenizers-0.21.0 torch-2.6.0 transformers-4.49.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: C:\\Users\\Mehmet\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#İlgili kütüphanelerin Kullanımı\n",
        "!pip install transformers torch peft datasets accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ir0jPeqz4JTs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: bitsandbytes 0.45.2\n",
            "Uninstalling bitsandbytes-0.45.2:\n",
            "  Successfully uninstalled bitsandbytes-0.45.2\n"
          ]
        }
      ],
      "source": [
        "#Bazen Bitsanbtyes kütüphanesinde sorun olabiliyor, kaldırmayı deneyin\n",
        "!pip uninstall bitsandbytes -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mrpSy9af4b5E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bitsandbytes in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.45.2)\n",
            "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bitsandbytes) (2.2.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#Bitsanbytes kurululumunu yeniden yapın. Daha sonra Google Colab'ı yeniden başlatın.\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unsloth\n",
            "  Using cached unsloth-2025.2.15-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.2.7 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (2025.2.7)\n",
            "Requirement already satisfied: torch>=2.4.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (2.6.0)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Using cached xformers-0.0.29.post3-cp311-cp311-win_amd64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: bitsandbytes in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.45.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (24.2)\n",
            "Requirement already satisfied: tyro in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.9.16)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (4.49.0)\n",
            "Requirement already satisfied: datasets>=2.16.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (3.3.2)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (7.0.0)\n",
            "Requirement already satisfied: wheel>=0.42.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (2.2.3)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (1.4.0)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.15.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.14.0)\n",
            "Requirement already satisfied: protobuf<4.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.29.1)\n",
            "Requirement already satisfied: hf_transfer in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.32.2)\n",
            "Collecting torchvision (from unsloth)\n",
            "  Using cached torchvision-0.21.0-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.34.1->unsloth) (0.5.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.4.0->unsloth) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->unsloth) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\n",
            "Requirement already satisfied: rich in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
            "Requirement already satisfied: cut_cross_entropy in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth_zoo>=2025.2.7->unsloth) (25.1.1)\n",
            "Requirement already satisfied: pillow in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth_zoo>=2025.2.7->unsloth) (11.1.0)\n",
            "Requirement already satisfied: importlib-metadata in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers->unsloth) (8.6.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tyro->unsloth) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tyro->unsloth) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.19.1)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Using cached unsloth-2025.2.15-py3-none-any.whl (188 kB)\n",
            "Using cached xformers-0.0.29.post3-cp311-cp311-win_amd64.whl (167.7 MB)\n",
            "Using cached torchvision-0.21.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
            "Installing collected packages: xformers, torchvision, unsloth\n",
            "Successfully installed torchvision-0.21.0 unsloth-2025.2.15 xformers-0.0.29.post3\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "#!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.21.0)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.6.0-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.2.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchaudio-2.6.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/2.5 MB 495.5 kB/s eta 0:00:05\n",
            "   - -------------------------------------- 0.1/2.5 MB 469.7 kB/s eta 0:00:06\n",
            "   -- ------------------------------------- 0.1/2.5 MB 722.1 kB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 0.2/2.5 MB 1.2 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 0.5/2.5 MB 2.0 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 0.9/2.5 MB 3.1 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.1/2.5 MB 3.4 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.1/2.5 MB 3.4 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.2/2.5 MB 2.5 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 1.2/2.5 MB 2.6 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.3/2.5 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.4/2.5 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.4/2.5 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.5/2.5 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 1.6/2.5 MB 2.2 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.7/2.5 MB 2.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.8/2.5 MB 2.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.9/2.5 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 2.0/2.5 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 2.1/2.5 MB 2.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.2/2.5 MB 2.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.4/2.5 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 2.3 MB/s eta 0:00:00\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-2.6.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: C:\\Users\\Mehmet\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unsloth in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2025.2.15)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.2.7 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (2025.2.7)\n",
            "Requirement already satisfied: torch>=2.4.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (2.6.0)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.0.29.post3)\n",
            "Requirement already satisfied: bitsandbytes in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.45.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (24.2)\n",
            "Requirement already satisfied: tyro in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.9.16)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (4.49.0)\n",
            "Requirement already satisfied: datasets>=2.16.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (3.3.2)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (7.0.0)\n",
            "Requirement already satisfied: wheel>=0.42.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (2.2.3)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (1.4.0)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.15.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.14.0)\n",
            "Requirement already satisfied: protobuf<4.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.29.1)\n",
            "Requirement already satisfied: hf_transfer in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.32.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth) (0.21.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate>=0.34.1->unsloth) (0.5.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets>=2.16.0->unsloth) (3.11.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface_hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.4.0->unsloth) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->unsloth) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\n",
            "Requirement already satisfied: rich in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
            "Requirement already satisfied: cut_cross_entropy in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth_zoo>=2025.2.7->unsloth) (25.1.1)\n",
            "Requirement already satisfied: pillow in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from unsloth_zoo>=2025.2.7->unsloth) (11.1.0)\n",
            "Requirement already satisfied: importlib-metadata in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers->unsloth) (8.6.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tyro->unsloth) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tyro->unsloth) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.19.1)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mehmet\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: C:\\Users\\Mehmet\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (24.0)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/1.8 MB 660.6 kB/s eta 0:00:03\n",
            "   - -------------------------------------- 0.1/1.8 MB 787.7 kB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 0.2/1.8 MB 1.5 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 0.3/1.8 MB 2.0 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 0.7/1.8 MB 3.4 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.1/1.8 MB 4.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 1.1/1.8 MB 3.5 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.2/1.8 MB 3.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.3/1.8 MB 3.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.4/1.8 MB 3.1 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.5/1.8 MB 3.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 1.7/1.8 MB 3.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 1.8/1.8 MB 3.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.8/1.8 MB 3.0 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "Successfully installed pip-25.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "NVIDIA RTX A5000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"GPU bulunamadı\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vKBRUNX3Zi-"
      },
      "source": [
        "## Veri Seti Kullanma\n",
        "Burada daha önce Selenium kullanılarak çeşitli internet sitelerinden kazınan CSV formatında veriler yer almaktadır. Bu veriler ALPACA formatında JSON olarak yeniden kaydedeceğiz. Kaggle ile indirdiğimiz veri setinin ismini ise değiştirin ve bunu yapın : Tum-Veri-Seti-Nisan2024-10.csv\n",
        "\n",
        "Eğer veri setinin ismini kendiniz belirlemek isterseniz koddaki ilgili alana dosya yolunu tam olarak yazınız."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiTlIrpSImzb"
      },
      "outputs": [],
      "source": [
        "#Veriyi indirin, burada sizin için daha öncesinde topladığım 114.000 satır veri vardır. Bu veriyi Google Colab içine ekleyin.\n",
        "#https://www.kaggle.com/datasets/denizhanahin/tr-dataset114k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def csv_to_alpaca(csv_file_path, output_json_path):\n",
        "    \"\"\"\n",
        "    CSV dosyasını Alpaca formatına dönüştürür ve JSON dosyasına kaydeder.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path (str): CSV dosyasının yolu.\n",
        "        output_json_path (str): Oluşturulacak JSON dosyasının yolu.\n",
        "    \"\"\"\n",
        "\n",
        "    # CSV dosyasını pandas DataFrame'ine oku\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "\n",
        "    # Alpaca formatına dönüştür\n",
        "    alpaca_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        alpaca_entry = {\n",
        "            \"instruction\": row[\"instruction\"],  # Başlık bilgisini \"instruction\" alanına ekle\n",
        "            \"input\": row[\"input\"],  # Özet bilgisini \"input\" alanına ekle\n",
        "            \"output\": row[\"output\"]  # İçerik bilgisini \"output\" alanına ekle\n",
        "        }\n",
        "        alpaca_data.append(alpaca_entry)\n",
        "\n",
        "    # JSON dosyasına kaydet\n",
        "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(alpaca_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Örnek kullanım\n",
        "csv_file_path = \"yeni_birlesik_alpaca_dataset.csv\"  # CSV dosyanızın adı\n",
        "output_json_path = \"alpaca_format.json\"  # Oluşturulacak JSON dosyasının adı\n",
        "csv_to_alpaca(csv_file_path, output_json_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmXqzOGv33VL"
      },
      "source": [
        "## Model Eğitimi - GPU\n",
        "Google Colab üzerinde kullandığınız GPU birimini kullanarak model eğitimi yapılacaktır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Os-z4oXtZIp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = \"senin token\"  # Hugging Face üzerinden ince ayar için kullanacağımız modeli indirmek için Hugging Face tokenı gerekmektedir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0dM1DTauNVV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.988 GB. Platform: Windows.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mehmet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\unsloth\\models\\llama.py:1277: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
            "  self.register_buffer(\"cos_cached\", emb.cos().to(dtype=dtype, device=device, non_blocking=True), persistent=False)\n"
          ]
        }
      ],
      "source": [
        "# Gerekli kütüphaneyi içe aktarma\n",
        "from unsloth import FastLanguageModel  # Unsloth kütüphanesinden hızlı model yükleme sınıfını içe aktarır, büyük dil modellerini optimize eder\n",
        "\n",
        "# PyTorch kütüphanesini içe aktarma\n",
        "import torch                           # PyTorch'u tensör işlemleri ve model hesaplamaları için içe aktarır\n",
        "\n",
        "# Maksimum dizi uzunluğu ayarı\n",
        "max_seq_length = 2048                  # Modelin bir seferde işleyebileceği maksimum token sayısını 2048 olarak tanımlar, RoPE Scaling ile otomatik ölçeklenir\n",
        "\n",
        "# Veri tipi ayarı\n",
        "#dtype = None                           # Veri tipini otomatik algılamaya bırakır; Tesla T4/V100 için Float16, Ampere+ için Bfloat16 seçilir\n",
        "dtype = torch.bfloat16 #A5000 ekran kartı için bunu seçtik.\n",
        "\n",
        "# 4-bit kuantizasyon ayarı\n",
        "load_in_4bit = True                    # Modeli 4-bit kuantizasyon ile yükler, bu bellek kullanımını azaltır ve performansı korur (False yapılırsa tam hassasiyet kullanılır)\n",
        "\n",
        "# 4-bit önceden kuantize edilmiş modellerin listesi\n",
        "fourbit_models = [                     # Unsloth’un desteklediği, 4-bit kuantize edilmiş modellerin listesi; hızlı indirme ve bellek tasarrufu sağlar\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 8B modeli, 15 trilyon token ile eğitilmiş, 2 kat hızlı\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",  # Llama-3.1 8B’nin talimatlara özel sürümü\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",     # Llama-3.1 70B modeli\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # Llama-3.1 405B modeli, 4-bit olarak yükleniyor\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # Mistral Nemo temel modeli, 12B, 2 kat hızlı\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",  # Mistral Nemo’nun talimat sürümü\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral 7B v0.3, 2 kat hızlı\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",   # Mistral 7B v0.3 talimat sürümü\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 mini, talimatlara özel, 2 kat hızlı\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",        # Phi-3 orta boy, 4k token kapasiteli\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",             # Gemma 2 9B modeli\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2 27B modeli, 2 kat hızlı\n",
        "]  # Daha fazla model için: https://huggingface.co/unsloth\n",
        "model_path = \"C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\Meta-Llama-3.1-8B-bnb-4bit\"\n",
        "\n",
        "# Modeli ve tokenizer'ı önceden eğitilmiş olarak yükleme\n",
        "model, tokenizer = FastLanguageModel.from_pretrained( \n",
        "   # force_download=True,\n",
        "      # Modeli ve tokenizer'ı yükler, Unsloth optimizasyonlarıyla\n",
        "    model_name=model_path,   # Yüklenecek modelin adı: LLaMA-3.1 8B (8 milyar parametre)\n",
        "    max_seq_length=max_seq_length,            # Maksimum dizi uzunluğunu 2048 olarak ayarlar\n",
        "    dtype=dtype,                              # Veri tipini otomatik algılamaya bırakır (Tesla T4 için Float16 olur)\n",
        "    load_in_4bit=load_in_4bit,                # 4-bit kuantizasyonu etkinleştirir, belleği optimize eder\n",
        "    #token = \"senin token\",                       # Eğer kısıtlı erişimli bir model kullanıyorsanız Hugging Face token’ı eklenir (burada pasif)\n",
        ")  # Model ve tokenizer nesnelerini döndürür"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tMTHc9ztYWZ"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------\n",
        "# 1. Google Drive Bağlantısı\n",
        "# ----------------------------------------------\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NT8-NvPBTXHc"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR =  \"C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim\" #Model verilerini kayıt edeceğiniz klasörü seçin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EJDRM5g1uZV5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
            "Unsloth 2025.2.15 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# Modeli LoRA ile yapılandırma\n",
        "model = FastLanguageModel.get_peft_model(  # Modeli LoRA ile optimize edilmiş bir PEFT (Parameter-Efficient Fine-Tuning) modeline dönüştürür\n",
        "    model,                                 # LoRA'nın uygulanacağı ana model (önceki adımda yüklenen model)\n",
        "    r=32,                                  # LoRA'nın rank değeri: 16’dan 32’ye artırıldı (RTX A5000’in 24 GB VRAM’i daha yüksek rank için yeterli, daha iyi performans için) eskisi ise 16\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],  # LoRA'nın uygulanacağı Transformer katmanları (dikkat mekanizması ve feed-forward katmanları, değişmedi)\n",
        "    lora_alpha=32,                         # LoRA'nın ölçeklendirme faktörü: 16’dan 32’ye artırıldı (r ile uyumlu, daha güçlü öğrenme için) eskisi ise 16\n",
        "    lora_dropout=0.05,                     # LoRA için dropout oranı: 0’dan 0.05’e artırıldı (büyük veri setinde overfitting riskine karşı) eskisi ise 0\n",
        "    bias=\"none\",                           # Bias ayarı: \"none\" (değişmedi, optimize edilmiş bir seçenek)\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Gradient checkpointing ayarı: \"unsloth\" (değişmedi, VRAM’i %30 azaltır, 2 kat büyük batch size sağlar)\n",
        "    random_state=3407,                     # Rastgele durum tohumu: 3407 (değişmedi, tekrarlanabilirlik için sabit)\n",
        "    use_rslora=True,                       # Rank Stabilized LoRA (RSLoRA) kullanımı: False’tan True’ya değiştirildi (stabiliteyi artırır, büyük veri setlerinde faydalı) eskisi ise False\n",
        "    loftq_config=None,                     # LoftQ (Low-Rank Factorized Quantization) yapılandırması: None (değişmedi, ihtiyaç yoksa ek optimizasyon gerekmez)\n",
        ")                                          # LoRA ile yapılandırılmış yeni modeli döndürür"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zZVebPk4up2w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 4763907 examples [03:33, 22352.13 examples/s]\n",
            "Map: 100%|██████████| 4763907/4763907 [01:50<00:00, 43286.27 examples/s] \n"
          ]
        }
      ],
      "source": [
        "# Alpaca formatı için prompt şablonu tanımlama\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"  # Üç bölümden oluşan bir şablon: talimat (instruction), giriş (input) ve cevap (response) yer tutucuları içerir\n",
        "\n",
        "# EOS_TOKEN tanımlama\n",
        "EOS_TOKEN = tokenizer.eos_token  # Tokenizer'dan EOS (End of Sequence) token'ını alır, metnin sonunu işaretler\n",
        "\n",
        "# Veri setini biçimlendirme fonksiyonu\n",
        "def formatting_prompts_func(examples):  # Veri setindeki örnekleri Alpaca formatına dönüştürmek için bir fonksiyon\n",
        "    instructions = examples[\"instruction\"]  # Veri setindeki \"instruction\" sütununu alır (talimatlar)\n",
        "    inputs       = examples[\"input\"]        # Veri setindeki \"input\" sütununu alır (girişler)\n",
        "    outputs      = examples[\"output\"]       # Veri setindeki \"output\" sütununu alır (cevaplar)\n",
        "    texts = []                              # Biçimlendirilmiş metinleri saklamak için boş bir liste oluşturur\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):  # Her bir talimat, giriş ve cevap üçlüsünü eşleştirir\n",
        "        # Alpaca şablonunu doldurur ve EOS_TOKEN ekler, yoksa üretim sonsuza dek devam eder!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN  # Şablonu doldurur ve metnin sonuna EOS token’ı ekler\n",
        "        texts.append(text)                  # Biçimlendirilmiş metni listeye ekler\n",
        "    return { \"text\" : texts, }              # \"text\" anahtarıyla biçimlendirilmiş metinleri bir sözlük olarak döndürür\n",
        "pass                                       # Boş bir \"pass\" ifadesi (gereksiz, fonksiyon zaten tamamlandı)\n",
        "\n",
        "# Veri setini yükleme ve işleme\n",
        "from datasets import load_dataset       # Hugging Face’in datasets kütüphanesini içe aktarır\n",
        "dataset = load_dataset(\"json\", data_files=\"C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\alpaca_format.json\")[\"train\"]  # JSON dosyasından veri setini yükler ve \"train\" bölümünü alır\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True,)  # Veri setine biçimlendirme fonksiyonunu toplu (batched) şekilde uygular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DVkWgOQfu5XT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting train dataset to ChatML (num_proc=2): 100%|██████████| 4763907/4763907 [01:09<00:00, 68575.55 examples/s]\n",
            "Applying chat template to train dataset (num_proc=2): 100%|██████████| 4763907/4763907 [01:15<00:00, 63517.55 examples/s]\n",
            "Tokenizing train dataset (num_proc=2): 100%|██████████| 4763907/4763907 [1:03:19<00:00, 1253.73 examples/s]\n",
            "Packing train dataset (num_proc=2): 100%|██████████| 4763907/4763907 [2:05:53<00:00, 630.72 examples/s]  \n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Gerekli kütüphaneleri içe aktarma\n",
        "from trl import SFTTrainer              # TRL kütüphanesinden SFTTrainer’ı içe aktarır, denetimli ince ayar için kullanılır\n",
        "from transformers import TrainingArguments  # Hugging Face Transformers’tan eğitim argümanlarını içe aktarır\n",
        "from unsloth import is_bfloat16_supported   # Unsloth’tan bfloat16 desteğini kontrol eden bir fonksiyon alır\n",
        "\n",
        "# Eğitim sürecini başlatmak için trainer nesnesi oluşturma\n",
        "trainer = SFTTrainer(                   # Modeli eğitmek için SFTTrainer nesnesi oluşturur\n",
        "    model=model,                        # Eğitilecek model (önceki adımlarda LoRA ile yapılandırılmış)\n",
        "    tokenizer=tokenizer,                # Modelin tokenizer’ı (metni token’lara çevirir)\n",
        "    train_dataset=dataset,              # Eğitim için kullanılacak veri seti (Alpaca formatında işlenmiş)\n",
        "    dataset_text_field=\"text\",          # Veri setindeki hangi sütunun kullanılacağı: \"text\" (biçimlendirilmiş prompt’lar)\n",
        "    max_seq_length=max_seq_length,      # Maksimum dizi uzunluğu (önceki adımda 2048 olarak tanımlı)\n",
        "    dataset_num_proc=2,                 # Veri işleme için kullanılacak işlemci sayısı: 2 (paralel処理 için)\n",
        "    packing=False,                      # Veri paketlemeyi devre dışı bırakır; kısa diziler için 5 kat hız artışı sağlayabilir ama burada kullanılmıyor\n",
        "    args=TrainingArguments(             # Eğitim argümanlarını tanımlar (aşağıda detaylı açıklanıyor)\n",
        "\n",
        "        per_device_train_batch_size=2,  # Her cihaz (GPU) için eğitim batch boyutu: 2 (küçük, bellek tasarrufu için)\n",
        "        gradient_accumulation_steps=4,  # Gradyan biriktirme adımları: 4 (efektif batch size’ı 2*4=8 yapar)\n",
        "        warmup_steps=5,                 # Öğrenme oranı ısınma adımları: 5 (başlangıçta öğrenme oranını yavaşça artırır)\n",
        "        # num_train_epochs=1,           # Tam bir epoch için eğitim (yorum satırı, şu anda kullanılmıyor)\n",
        "        max_steps=60,                   # Toplam eğitim adımı sayısı: 60 (epoch yerine adım bazlı eğitim)\n",
        "        learning_rate=2e-4,             # Öğrenme oranı: 0.0002 (modelin ne kadar hızlı öğreneceğini belirler)\n",
        "        fp16=not is_bfloat16_supported(),  # Float16 kullanımı: bfloat16 desteklenmiyorsa True (Tesla T4 için geçerli)\n",
        "        bf16=is_bfloat16_supported(),   # Bfloat16 kullanımı: destekleniyorsa True (Ampere GPU’lar için)\n",
        "        logging_steps=1,                # Log kayıt sıklığı: her 1 adımda bir (eğitim ilerlemesini izlemek için)\n",
        "        optim=\"adamw_8bit\",             # Optimize edici: 8-bit AdamW (bellek verimli bir versiyon)\n",
        "        weight_decay=0.01,              # Ağırlık çürümesi: 0.01 (overfitting’i önlemek için regularization)\n",
        "        lr_scheduler_type=\"linear\",     # Öğrenme oranı zamanlayıcısı: doğrusal (lineer bir şekilde azalır)\n",
        "        seed=3407,                      # Rastgele tohum: 3407 (tekrarlanabilirlik için)\n",
        "        output_dir=CHECKPOINT_DIR,           # Çıktıların kaydedileceği dizin: \"CHECKPOINT_DIR\"\n",
        "        report_to=\"none\",               # Eğitim raporlama: \"none\" (WandB gibi araçlar kullanılmayacak)\n",
        "    ),                                  # Eğitim argümanlarını tamamlar\n",
        ")                                       # Trainer nesnesini oluşturur\n",
        "\"\"\"\n",
        "\n",
        "# Gerekli kütüphaneleri içe aktarma\n",
        "from trl import SFTTrainer              # TRL kütüphanesinden SFTTrainer’ı içe aktarır, denetimli ince ayar için kullanılır\n",
        "from transformers import TrainingArguments  # Hugging Face Transformers’tan eğitim argümanlarını içe aktarır\n",
        "from unsloth import is_bfloat16_supported   # Unsloth’tan bfloat16 desteğini kontrol eden bir fonksiyon alır\n",
        "\n",
        "# Eğitim sürecini başlatmak için trainer nesnesi oluşturma\n",
        "trainer = SFTTrainer(                   # Modeli eğitmek için SFTTrainer nesnesi oluşturur\n",
        "    model=model,                        # Eğitilecek model (önceki adımlarda LoRA ile yapılandırılmış)\n",
        "    tokenizer=tokenizer,                # Modelin tokenizer’ı (metni token’lara çevirir)\n",
        "    train_dataset=dataset,              # Eğitim için kullanılacak veri seti (Alpaca formatında işlenmiş)\n",
        "    dataset_text_field=\"text\",          # Veri setindeki hangi sütunun kullanılacağı: \"text\" (biçimlendirilmiş prompt’lar)\n",
        "    max_seq_length=2048,                # Maksimum dizi uzunluğu (önceki adımda 2048 olarak tanımlı, uzun bağlamlar için yeterli)\n",
        "    dataset_num_proc=2,                 # Veri işleme için kullanılacak işlemci sayısı: 4 (RTX A5000’in gücüyle paralel işleme artırıldı, 5 milyon satır için daha hızlı)\n",
        "    packing=True,                       # Veri paketlemeyi etkinleştirir; kısa diziler için 5x hız artışı sağlar, büyük veri setinde faydalı\n",
        "    args=TrainingArguments(             # Eğitim argümanlarını tanımlar\n",
        "        per_device_train_batch_size=8,  # Her cihaz (GPU) için eğitim batch boyutu: 8 (24 GB VRAM ile mümkün, performans artırıldı)\n",
        "        gradient_accumulation_steps=4,  # Gradyan biriktirme adımları: 4 (efektif batch size’ı 8*4=32 yapar, bellek yönetimi için)\n",
        "        warmup_steps=100,               # Öğrenme oranı ısınma adımları: 100 (büyük veri seti için daha yavaş ve stabil ısınma, 5’ten artırıldı)\n",
        "        num_train_epochs=2,           # Tam bir epoch için eğitim (yorum satırı, şu anda kullanılmıyor, veri seti büyük olduğu için adım bazlı tercih ediliyor)\n",
        "        max_steps=1000,                 # Toplam eğitim adımı sayısı: 1000 (60’tan artırıldı, 5 milyon satır için yeterli öğrenme sağlamak için)\n",
        "        learning_rate=2e-4,             # Öğrenme oranı: 0.0002 (modelin ne kadar hızlı öğreneceğini belirler, büyük veri setinde uygun)\n",
        "        fp16=not is_bfloat16_supported(),  # Float16 kullanımı: bfloat16 desteklenmiyorsa True (RTX A5000’de bfloat16 destekleniyor)\n",
        "        bf16=is_bfloat16_supported(),   # Bfloat16 kullanımı: destekleniyorsa True (Ampere mimarisi için RTX A5000’de etkin, daha verimli)\n",
        "        logging_steps=10,               # Log kayıt sıklığı: her 10 adımda bir (1’den artırıldı, büyük veri setinde log sıklığını azaltır)\n",
        "        optim=\"adamw_8bit\",             # Optimize edici: 8-bit AdamW (bellek verimli bir versiyon, değişmedi)\n",
        "        weight_decay=0.01,              # Ağırlık çürümesi: 0.01 (overfitting’i önlemek için regularization, değişmedi)\n",
        "        lr_scheduler_type=\"linear\",     # Öğrenme oranı zamanlayıcısı: doğrusal (lineer bir şekilde azalır, değişmedi)\n",
        "        seed=3407,                      # Rastgele tohum: 3407 (tekrarlanabilirlik için, değişmedi)\n",
        "        output_dir=CHECKPOINT_DIR,      # Çıktıların kaydedileceği dizin: \"CHECKPOINT_DIR\" (değişmedi)\n",
        "        report_to=\"none\",               # Eğitim raporlama: \"none\" (WandB gibi araçlar kullanılmayacak, değişmedi)\n",
        "    ),                                  # Eğitim argümanlarını tamamlar\n",
        ")                                       # Trainer nesnesini oluşturur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim/final_model\\\\tokenizer_config.json',\n",
              " 'C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim/final_model\\\\special_tokens_map.json',\n",
              " 'C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim/final_model\\\\tokenizer.json')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(f\"{CHECKPOINT_DIR}/final_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4EpKnvthvRga"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint aranıyor...\n",
            "Hata: No valid checkpoint found in output directory (C:\\Users\\Mehmet\\Desktop\\Denizhan\\model_egitim)...\n",
            "Yeni eğitim başlatılıyor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 2,324,213 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 32 | Total steps = 1,000\n",
            " \"-____-\"     Number of trainable parameters = 83,886,080\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 14:23:29, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.803600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.799800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.699400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.739000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.681300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.658600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.671700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.702500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.674400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.705200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.685500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.624700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.619900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.613800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.602500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.657500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.622200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.661400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.614400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.693100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.627600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.663000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.592700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.634800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.655800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.644300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.658100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.610600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.648800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.669700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.622200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.623900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.595400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.610800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.627000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.628400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>1.573700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>1.590200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.675500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.627600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.575500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>1.614300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.600700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.610600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>1.625300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.632300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>1.605800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.594000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>1.589900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.602800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>1.622400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>1.671700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.605000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.604500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>1.658600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>1.576800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>1.600400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.559900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>1.630900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>1.663400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>1.595100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>1.596900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>1.578900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>1.607700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>1.592800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>1.608600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.580200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>1.617600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>1.613900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>1.590800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>1.613700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>1.625300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>1.622700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>1.615400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>1.571500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.571500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>1.593300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>1.579300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>1.564600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>1.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.590800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>1.570900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>1.580500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>1.603100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>1.649300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.595900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ----------------------------------------------\n",
        "# 9. Eğitimi Başlat\n",
        "# ----------------------------------------------\n",
        "try:                                    # Hata yakalama bloğu başlatır, checkpoint ile devam etmeyi dener\n",
        "    print(\"Checkpoint aranıyor...\")     # Kullanıcıya checkpoint’in arandığını bildirir\n",
        "    trainer.train(resume_from_checkpoint=True)  # Eğitime son checkpoint’ten devam etmeyi dener (önceki bir eğitim varsa)\n",
        "except Exception as e:                  # Eğer bir hata oluşursa (örneğin, checkpoint bulunamazsa) bu blok çalışır\n",
        "    print(f\"Hata: {str(e)[:200]}...\\nYeni eğitim başlatılıyor...\")  # Hatanın ilk 200 karakterini yazdırır ve yeni eğitime geçeceğini bildirir\n",
        "    trainer.train()                     # Sıfırdan yeni bir eğitim başlatır (checkpoint olmadan)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGo9NKBT6mWM"
      },
      "source": [
        "## Model Eğitimini Kaydetme\n",
        "Model eğitimi bittiğinde tüm veriler cihazınızda kayıtlı olacaktır. Bu verileri Hugging Face içine yükleyip çalıştırabilirsiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gw5-Xa1iyArI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eğitim tamamlandı. Model şu adreste kaydedildi: C:\\Users\\Mehmet\\Desktop\\Denizhan\\model_egitim/final_model\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------------------------\n",
        "# 10. Modeli Kaydet\n",
        "# ----------------------------------------------\n",
        "model.save_pretrained(f\"{CHECKPOINT_DIR}/final_model\")  # Eğitilmiş modeli belirtilen dizine kaydeder (CHECKPOINT_DIR/final_model)\n",
        "tokenizer.save_pretrained(f\"{CHECKPOINT_DIR}/final_model\")  # Tokenizer’ı aynı dizine kaydeder\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 11. Opsiyonel: Eğitim İlerlemesini İzleme ve Log Kaydetme\n",
        "# ----------------------------------------------\n",
        "trainer.save_model(f\"{CHECKPOINT_DIR}/final_checkpoint\")  # Eğitim sırasında ara checkpoint’leri kaydet (opsiyonel, büyük veri seti için faydalı)\n",
        "print(f\"Eğitim tamamlandı. Model şu adreste kaydedildi: {CHECKPOINT_DIR}/final_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (39/39 shards): 100%|██████████| 2324213/2324213 [00:15<00:00, 150093.76 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Token’lanmış veri setini kaydet\n",
        "trainer.train_dataset.save_to_disk(f\"{CHECKPOINT_DIR}/final_model/tokenized_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osqcw_wL7Ddi"
      },
      "source": [
        "## PEFT ve LORA ile Ana Modeli Birleştirme - Burayı en son çalıştır ama gerek olmayabilir.\n",
        "Yukarıdaki model eğitiminde LORA ve PEFT ile ince ayar yaptık. Burada ise bize bazı dosyalar oluşturdu. Şimdi ise model eğitimi için kullandığımız ana model ile eğitim sonuçlarını birleştirmemiz gerekmektedir. Bu sayede ince ayar yaptığımız modeli rahatça kullanabileceğiz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9ustrbH82wQ0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.988 GB. Platform: Windows.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mehmet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\peft\\tuners\\lora\\bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim/merged_model\\\\tokenizer_config.json',\n",
              " 'C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim/merged_model\\\\special_tokens_map.json',\n",
              " 'C:\\\\Users\\\\Mehmet\\\\Desktop\\\\Denizhan\\\\model_egitim/merged_model\\\\tokenizer.json')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from peft import PeftModel\n",
        "\n",
        "# Step 1: Load the base model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_path,  # Path to the base model\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "# Step 2: Load the LoRA adapters using PEFT\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    f\"{CHECKPOINT_DIR}/final_model\"  # Path to the LoRA checkpoint\n",
        ")\n",
        "\n",
        "# Step 3: Merge LoRA into the base model and unload\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Step 4: Save the merged model\n",
        "model.save_pretrained(f\"{CHECKPOINT_DIR}/merged_model\")\n",
        "tokenizer.save_pretrained(f\"{CHECKPOINT_DIR}/merged_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb3u92le3X0X"
      },
      "source": [
        "## Model Eğitimini Kaydetme\n",
        "Model eğitimi bittiğinde tüm veriler cihazınızda kayıtlı olacaktır. Bu verileri Hugging Face içine yükleyip çalıştırabilirsiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBgTsRA33R-1"
      },
      "outputs": [],
      "source": [
        "huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1IP9hpP3Tqf"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_dan7ZO3wGZ"
      },
      "outputs": [],
      "source": [
        "# Birleşik modeli push et\n",
        "model.push_to_hub(\"kullanici_adi/merged_model\")\n",
        "tokenizer.push_to_hub(\"kullanici_adi/merged_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbOj5DtM8ZMK"
      },
      "source": [
        "## Model Çalıştırma\n",
        "Artık ince ayar yaptığımız ve gerekli düzenlemeleri yaptığımız modelimizi çalıştırabiliriz. Daha önce Hugging Face üzerine yüklediğimiz modeli çalıştıralım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p5DhMblt4DWD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nContinue the fibonnaci sequence.\\n\\n### Input:\\n1, 1, 2, 3, 5, 8\\n\\n### Response:\\n13<|end_of_text|>']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alpaca_prompt = Yukarıdan kopyalandı\n",
        "# Alpaca formatında prompt şablonunun daha önce tanımlandığını varsayar (instruction, input, response içeren)\n",
        "\n",
        "# Modeli tahmin moduna geçirme\n",
        "FastLanguageModel.for_inference(model)  # Modeli inference için hazırlar, Unsloth’un 2 kat hızlı yerel tahmin özelliğini etkinleştirir\n",
        "\n",
        "# Girişi hazırlama ve tokenize etme\n",
        "inputs = tokenizer(                     # Tokenizer ile giriş metnini token’lara çevirir\n",
        "    [                                   # Tek bir prompt’u liste içinde işler\n",
        "        alpaca_prompt.format(           # Alpaca şablonunu belirli değerlerle doldurur\n",
        "            \"Continue the fibonnaci sequence.\",  # Talimat: Fibonacci dizisini devam ettir\n",
        "            \"1, 1, 2, 3, 5, 8\",        # Giriş: Dizinin başlangıç kısmı\n",
        "            \"\",                         # Çıkış: Boş bırakılır, modelin üretmesi için\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\"                 # Çıktıyı PyTorch tensör formatında döndürür\n",
        ").to(\"cuda\")                            # Tensörleri CUDA (GPU) belleğine taşır\n",
        "\n",
        "# Model ile tahmin yapma\n",
        "outputs = model.generate(               # Modeli kullanarak metin üretir\n",
        "    **inputs,                           # Tokenize edilmiş girişleri modele verir\n",
        "    max_new_tokens=512,                  # Üretilecek maksimum yeni token sayısı: 64\n",
        "    use_cache=True                      # Önbellek kullanımını etkinleştirir, hızı artırır\n",
        ")\n",
        "\n",
        "# Çıktıyı decode etme\n",
        "tokenizer.batch_decode(outputs)         # Üretilen token’ları insan tarafından okunabilir metne çevirir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# alpaca_prompt = Yukarıdan kopyalandı\n",
        "# Alpaca formatında prompt şablonunun daha önce tanımlandığını varsayar (instruction, input, response içeren)\n",
        "\n",
        "# Modeli tahmin moduna geçirme\n",
        "FastLanguageModel.for_inference(model)  # Modeli inference için hazırlar, Unsloth’un 2 kat hızlı yerel tahmin özelliğini etkinleştirir\n",
        "\n",
        "# Girişi hazırlama ve tokenize etme\n",
        "inputs = tokenizer(                     # Tokenizer ile giriş metnini token’lara çevirir\n",
        "    [                                   # Tek bir prompt’u liste içinde işler\n",
        "        alpaca_prompt.format(           # Alpaca şablonunu belirli değerlerle doldurur\n",
        "            \"Continue the fibonnaci sequence.\",  # Talimat: Fibonacci dizisini devam ettir\n",
        "            \"1, 1, 2, 3, 5, 8\",        # Giriş: Dizinin başlangıç kısmı\n",
        "            \"\",                         # Çıkış: Boş bırakılır, modelin üretmesi için\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\"                 # Çıktıyı PyTorch tensör formatında döndürür\n",
        ").to(\"cuda\")                            # Tensörleri CUDA (GPU) belleğine taşır\n",
        "\n",
        "# Model ile tahmin yapma\n",
        "outputs = model.generate(               # Modeli kullanarak metin üretir\n",
        "    **inputs,                           # Tokenize edilmiş girişleri modele verir\n",
        "    max_new_tokens=512,                  # Üretilecek maksimum yeni token sayısı: 64\n",
        "    use_cache=True                      # Önbellek kullanımını etkinleştirir, hızı artırır\n",
        ")\n",
        "\n",
        "# Çıktıyı decode etme\n",
        "tokenizer.batch_decode(outputs)         # Üretilen token’ları insan tarafından okunabilir metne çevirir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Fenerbahçe'nin son maçlarının sonuçlarını listele.\n",
            "\n",
            "### Input:\n",
            "Son 5 maçın takımları: Fenerbahçe vs. Kasımpaşa, Anderlecht vs. Fenerbahçe, Alanyaspor vs. Fenerbahçe, Fenerbahçe vs. Erzurum FK, Fenerbahçe vs. Göztepe\n",
            "\n",
            "### Response:\n",
            "Fenerbahçe 3, Kasımpaşa 1\n",
            "Anderlecht 1, Fenerbahçe 1\n",
            "Alanyaspor 2, Fenerbahçe 1\n",
            "Fenerbahçe 2, Erzurum FK 0\n",
            "Fenerbahçe 1, Göztepe 0\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Yukarıdan kopyalandı\n",
        "# Alpaca formatında prompt şablonunun daha önce tanımlandığını varsayar (instruction, input, response içeren)\n",
        "\n",
        "# Modeli tahmin moduna geçirme\n",
        "FastLanguageModel.for_inference(model)  # Modeli inference için hazırlar, Unsloth’un 2 kat hızlı yerel tahmin özelliğini etkinleştirir\n",
        "\n",
        "# Girişi hazırlama ve tokenize etme\n",
        "inputs = tokenizer(                     # Tokenizer ile giriş metnini token’lara çevirir\n",
        "    [                                   # Tek bir prompt’u liste içinde işler\n",
        "        alpaca_prompt.format(           # Alpaca şablonunu belirli değerlerle doldurur\n",
        "            \"Fenerbahçe'nin son maçlarının sonuçlarını listele.\",  # Talimat: Fenerbahçe'nin maç sonuçlarını listele\n",
        "            \"Son 5 maçın takımları: Fenerbahçe vs. Kasımpaşa, Anderlecht vs. Fenerbahçe, Alanyaspor vs. Fenerbahçe, Fenerbahçe vs. Erzurum FK, Fenerbahçe vs. Göztepe\",  # Giriş: Son maçların takımları\n",
        "            \"\",                         # Çıkış: Boş bırakılır, modelin üretmesi için\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\"                 # Çıktıyı PyTorch tensör formatında döndürür\n",
        ").to(\"cuda\")                            # Tensörleri CUDA (GPU) belleğine taşır\n",
        "\n",
        "# Model ile tahmin yapma\n",
        "outputs = model.generate(               # Modeli kullanarak metin üretir\n",
        "    **inputs,                           # Tokenize edilmiş girişleri modele verir\n",
        "    max_new_tokens=512,                 # Üretilecek maksimum yeni token sayısı: Daha fazla bilgi için artırdım\n",
        "    use_cache=True                      # Önbellek kullanımını etkinleştirir, hızı artırır\n",
        ")\n",
        "\n",
        "# Çıktıyı decode etme ve yazdırma\n",
        "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # Üretilen token’ları insan tarafından okunabilir metne çevirir, özel token’ları atlar\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Fenerbahçe'nin son maçlarının sonuçlarını listele ve her maç için kısa bir açıklama yap.\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "Fenerbahçe, son maçlarından 3 galibiyet, 2 beraberlik ve 1 mağlubiyet aldı. Bu sonuçlar, takımın ligde iyi bir performans gösterdiğini ve önemli maçlarda da başarılı olduğunu gösteriyor.\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Yukarıdan kopyalandığını varsayıyorum\n",
        "# Alpaca formatında prompt şablonunun \"instruction\", \"input\", \"response\" alanlarını içerdiğini kabul ediyorum\n",
        "\n",
        "# Modeli tahmin moduna geçirme\n",
        "FastLanguageModel.for_inference(model)  # Modeli inference için hazırlar, Unsloth’un 2 kat hızlı yerel tahmin özelliğini etkinleştirir\n",
        "\n",
        "# Girişi hazırlama ve tokenize etme\n",
        "inputs = tokenizer(                     # Tokenizer ile giriş metnini token’lara çevirir\n",
        "    [                                   # Tek bir prompt’u liste içinde işler\n",
        "        alpaca_prompt.format(           # Alpaca şablonunu belirli değerlerle doldurur\n",
        "            \"Fenerbahçe'nin son maçlarının sonuçlarını listele ve her maç için kısa bir açıklama yap.\",  # Talimat: Maç sonuçlarını listele ve açıklama ekle\n",
        "            \"\",                         # Giriş: Boş bırakıldı, model kendi bilgisine dayanacak\n",
        "            \"\",                         # Çıkış: Boş bırakılır, modelin üretmesi için\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\"                 # Çıktıyı PyTorch tensör formatında döndürür\n",
        ").to(\"cuda\")                            # Tensörleri CUDA (GPU) belleğine taşır\n",
        "\n",
        "# Model ile tahmin yapma\n",
        "outputs = model.generate(               # Modeli kullanarak metin üretir\n",
        "    **inputs,                           # Tokenize edilmiş girişleri modele verir\n",
        "    max_new_tokens=512,                 # Üretilecek maksimum yeni token sayısı: Daha fazla ayrıntı için 512\n",
        "    use_cache=True                      # Önbellek kullanımını etkinleştirir, hızı artırır\n",
        ")\n",
        "\n",
        "# Çıktıyı decode etme ve yazdırma\n",
        "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # Üretilen token’ları insan tarafından okunabilir metne çevirir, özel token’ları atlar\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Fenerbahçe nasıl bir takımdır? Oyuncuları kimlerdir?\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "Fenerbahçe, 1907 yılında İstanbul'da kurulmuş Türk futbol kulübüdür. Fenerbahçe, 1907 yılında kurulan kulüpler arasında en çok şampiyonluğa ulaşan kulüp unvanına sahiptir. 1991 yılında Avrupa Şampiyon Kulüpler Kupası'nda final oynayan tek Türk kulübüdür. Fenerbahçe'nin 2008-2009 sezonunda UEFA Avrupa Ligi'nde final oynayan ilk Türk kulübü olduğu da bilinmektedir. Fenerbahçe'nin renkleri kırmızı ve beyazdır. Fenerbahçe'nin en çok maç yaptığı ve en çok kazandığı takımı ise Trabzonspor'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir ise İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe'nin en çok kazandığı ve en çok oynadığı şehir İstanbul'dur. Fenerbahçe\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Yukarıdan kopyalandığını varsayıyorum\n",
        "# Alpaca formatında prompt şablonunun \"instruction\", \"input\", \"response\" alanlarını içerdiğini kabul ediyorum\n",
        "\n",
        "# Modeli tahmin moduna geçirme\n",
        "FastLanguageModel.for_inference(model)  # Modeli inference için hazırlar, Unsloth’un 2 kat hızlı yerel tahmin özelliğini etkinleştirir\n",
        "\n",
        "# Girişi hazırlama ve tokenize etme\n",
        "inputs = tokenizer(                     # Tokenizer ile giriş metnini token’lara çevirir\n",
        "    [                                   # Tek bir prompt’u liste içinde işler\n",
        "        alpaca_prompt.format(           # Alpaca şablonunu belirli değerlerle doldurur\n",
        "            \"Fenerbahçe nasıl bir takımdır? Oyuncuları kimlerdir?\",  # Talimat: Maç sonuçlarını listele ve açıklama ekle\n",
        "            \"\",                         # Giriş: Boş bırakıldı, model kendi bilgisine dayanacak\n",
        "            \"\",                         # Çıkış: Boş bırakılır, modelin üretmesi için\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\"                 # Çıktıyı PyTorch tensör formatında döndürür\n",
        ").to(\"cuda\")                            # Tensörleri CUDA (GPU) belleğine taşır\n",
        "\n",
        "# Model ile tahmin yapma\n",
        "outputs = model.generate(               # Modeli kullanarak metin üretir\n",
        "    **inputs,                           # Tokenize edilmiş girişleri modele verir\n",
        "    max_new_tokens=2048,                # Üretilecek maksimum yeni token sayısı: Daha fazla ayrıntı için 512\n",
        "    use_cache=True                      # Önbellek kullanımını etkinleştirir, hızı artırır\n",
        ")\n",
        "\n",
        "# Çıktıyı decode etme ve yazdırma\n",
        "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # Üretilen token’ları insan tarafından okunabilir metne çevirir, özel token’ları atlar\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIdtUXoR4LGL"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"denizzhansahin/gemma2bDeneme\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"denizzhansahin/gemma2bDeneme\")\n",
        "\n",
        "input_text = \"Fenerbahçe nasıl bir takımdır?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**input_ids)\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
